{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Curso: Bioestat√≠stica ‚Äî An√°lise de Medidas Repetidas\n",
        "## Autores: Sandro Camargo e Fernando Cardoso\n",
        "\n",
        "**Problema**:\n",
        "Comparar o crescimento de bovinos de diferentes gen√≥tipos, 24 novilhos de vacas Angus inseminadas com touros de tr√™s ra√ßas zebuƒ±ÃÅnas: Brahman, Nelore e Tabapu√£;\n",
        "\n",
        "Os novilhos foram criados em condi√ß√µes extensivas,\n",
        "exclusivamente sob pastagem nativa, em campos\n",
        "experimentais da Embrapa Pecu√°ria Sul (Bag√©/RS);\n",
        "\n",
        "Os novilhos foram pesados em cinco perƒ±ÃÅodos:\n",
        "* Desmama (‚àº 6 meses de idade)\n",
        "* Ano (‚àº 12 meses)\n",
        "* Sobreano (‚àº 18 meses)\n",
        "* Ao final da recria (‚àº 36 meses)\n",
        "* Antes do abate (‚àº 39 meses)\n",
        "\n",
        "A base de dados est√° dispon√≠vel [aqui](https://github.com/Sandrocamargo/biostatistics/blob/master/datasets/medidasrepetidas-cruzas.csv).\n",
        "\n",
        "Abra este c√≥digo no seu google colab [clicando aqui](https://colab.research.google.com/github/Sandrocamargo/biostatistics/blob/master/python/bioe_09_Medidas_Repetidas.ipynb)."
      ],
      "metadata": {
        "id": "YJZPFpl8ITZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üß© Contexto: An√°lise de Medidas Repetidas**\n",
        "\n",
        "Quando se mede uma mesma unidade experimental, que pode ser um animal ou planta, em v√°rios momentos, as observa√ß√µes n√£o s√£o independentes, ou seja, existe correla√ß√£o intraindiv√≠duo.\n",
        "\n",
        "Os modelos mistos tratam isso explicitamente, decompondo a varia√ß√£o em:\n",
        "\n",
        "* Efeito fixo: o padr√£o m√©dio da popula√ß√£o (ex.: efeito do tempo, do tratamento, da ra√ßa, etc.)\n",
        "\n",
        "* Efeito aleat√≥rio: as varia√ß√µes individuais (ex.: cada UE tem um ponto de partida e ritmo de crescimento pr√≥prio)\n",
        "\n",
        "**‚öôÔ∏è Modelo com intercepto aleat√≥rio**\n",
        "\n",
        "a) Random-intercept model\n",
        "\n",
        "$Peso $$\\sim$$ Tempo + (1 | Animal)$\n",
        "\n",
        "‚û°Ô∏è Este modelo permite que cada indiv√≠duo tenha um valor inicial (intercepto) diferente, mas assume que a inclina√ß√£o (a taxa de mudan√ßa ao longo do tempo) √© igual para todos.\n",
        "\n",
        "üß† Interpreta√ß√£o:\n",
        "\n",
        "* Boa aproxima√ß√£o quando todos os indiv√≠duos seguem curvas paralelas (mesma tend√™ncia temporal, apenas deslocadas verticalmente).\n",
        "* A correla√ß√£o intraindiv√≠duo √© constante, o que equivale a um modelo com estrutura de covari√¢ncia ‚Äúcompound symmetry‚Äù (CS).\n",
        "\n",
        "**üìà Modelo com intercepto + inclina√ß√£o aleat√≥rios**\n",
        "\n",
        "b) Random-intercept + random-slope model\n",
        "\n",
        "$Peso $$\\sim$$ Tempo + (Tempo | Animal)$\n",
        "\n",
        "‚û°Ô∏è Este modelo permite que cada indiv√≠duo tenha n√£o s√≥ um ponto de partida diferente, mas tamb√©m uma inclina√ß√£o (tend√™ncia temporal) diferente.\n",
        "\n",
        "üß† Interpreta√ß√£o:\n",
        "\n",
        "* Cada indiv√≠duo pode crescer ou evoluir em ritmo distinto.\n",
        "* A correla√ß√£o entre medidas depende da dist√¢ncia no tempo (semelhante √† estrutura AR(1)).\n",
        "* √â mais realista quando h√° evid√™ncia de que as respostas dos indiv√≠duos divergem ao longo do tempo.\n",
        "\n",
        "**üßÆ Por que testar os dois?**\n",
        "\n",
        "O modelo com apenas intercepto aleat√≥rio √© mais simples, com menos par√¢metros e mais est√°vel numericamente.\n",
        "\n",
        "O modelo com intercepto + inclina√ß√£o aleat√≥rios √© mais flex√≠vel, mas pode n√£o convergir (como no seu caso) se o conjunto de dados for pequeno ou houver multicolinearidade.\n",
        "\n",
        "Por isso, o procedimento padr√£o √©:\n",
        "* Ajustar o modelo mais simples (random intercept).\n",
        "* Testar o modelo mais complexo (random slope).\n",
        "* Comparar via teste de raz√£o de verossimilhan√ßa (LRT) ou AIC/BIC.\n",
        "* Se o modelo com slope aleat√≥rio melhora significativamente o ajuste ‚Üí mantenha-o.\n",
        "* Caso contr√°rio ‚Üí o modelo mais simples √© suficiente.\n",
        "\n",
        "**üß≠ Analogia intuitiva**\n",
        "\n",
        "Tendo-se o peso de 24 animais em 5 datas:\n",
        "* No modelo com intercepto aleat√≥rio, voc√™ sup√µe que todos crescem na mesma taxa, apenas come√ßam mais leves ou mais pesados.\n",
        "* No modelo com intercepto + slope aleat√≥rios, voc√™ admite que cada animal tem um ritmo de crescimento pr√≥prio."
      ],
      "metadata": {
        "id": "OPO9l_Y9lVlx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQd_EPME7zvq"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "!pip install pingouin\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pingouin as pg\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.formula.api import mixedlm\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "from scipy.stats import shapiro, levene\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 0. Config\n",
        "# ---------------------------\n",
        "plt.style.use(\"seaborn-v0_8-white\")\n",
        "DATA_PATH = \"https://raw.githubusercontent.com/Sandrocamargo/biostatistics/refs/heads/master/datasets/medidasrepetidas-cruzas.csv\"  # change if needed"
      ],
      "metadata": {
        "id": "NT4k9Of9GGB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga e inspe√ß√£o dos dados"
      ],
      "metadata": {
        "id": "odX8Lmi0HEPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.read_csv(DATA_PATH, sep=\";\", header=0)\n",
        "# Ensure columns names match your file: Animal, Raca_touro, Data, Peso\n",
        "# Convert types\n",
        "dados[\"Animal\"] = dados[\"Animal\"].astype(\"category\")\n",
        "dados[\"Raca_touro\"] = dados[\"Raca_touro\"].astype(\"category\")\n",
        "\n",
        "# Convert Data string to datetime\n",
        "dados[\"Datad\"] = pd.to_datetime(dados[\"Data\"], errors=\"coerce\")\n",
        "\n",
        "# Create numeric date (days since first measurement) for use in random slopes or AR(1) approximations\n",
        "dados[\"Datad_num\"] = (dados[\"Datad\"] - dados[\"Datad\"].min()).dt.days\n",
        "\n",
        "dados.info()\n",
        "dados.head()"
      ],
      "metadata": {
        "id": "v_3zs7aYGH78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An√°lise explorat√≥ria de dados"
      ],
      "metadata": {
        "id": "l_I-yIMSHO7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter of Peso vs date (convert date to numeric for regression line)\n",
        "dados[\"Datad_ordinal\"] = dados[\"Datad\"].dropna().map(pd.Timestamp.toordinal)\n",
        "g = sns.scatterplot(data=dados, x=\"Datad\", y=\"Peso\", hue=\"Raca_touro\")\n",
        "plt.title(\"Peso by Date and Bull Breed\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.savefig(\"pesos_by_date.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Mean trajectory by group\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.lineplot(data=dados, x=\"Datad\", y=\"Peso\", hue=\"Raca_touro\", estimator=\"mean\", marker=\"o\")\n",
        "plt.title(\"Mean Peso by Date and Raca_touro\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.savefig(\"mean_peso_by_group.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Individual trajectories\n",
        "plt.figure(figsize=(10,6))\n",
        "for (raca, animal), df in dados.groupby([\"Raca_touro\",\"Animal\"]):\n",
        "    plt.plot(df[\"Datad\"], df[\"Peso\"], color=sns.color_palette(\"tab10\")[list(dados.Raca_touro.cat.categories).index(raca)], alpha=0.6)\n",
        "plt.title(\"Individual weight trajectories (colored by Raca_touro)\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.savefig(\"individual_trajectories.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Boxplot by date and by date x breed\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.boxplot(x=\"Datad\", y=\"Peso\", data=dados)\n",
        "plt.xticks(rotation=30)\n",
        "plt.title(\"Boxplot Peso by Date\")\n",
        "plt.savefig(\"boxplot_by_date.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eilH6bTKGJ2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correla√ß√µes entre datas"
      ],
      "metadata": {
        "id": "wybmy_8uHWs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dates = sorted(dados[\"Datad\"].dropna().unique())\n",
        "print(\"Dates in dataset:\", dates)\n",
        "# compute pairwise correlations between measurements at two dates if data are balanced/alignable\n",
        "if len(dates) >= 2:\n",
        "    for d in dates[1:]:\n",
        "        a = dados.loc[dados[\"Datad\"]==dates[0], [\"Animal\",\"Peso\"]].set_index(\"Animal\")\n",
        "        b = dados.loc[dados[\"Datad\"]==d, [\"Animal\",\"Peso\"]].set_index(\"Animal\")\n",
        "        joined = a.join(b, how=\"inner\", lsuffix=\"_t1\", rsuffix=\"_t2\")\n",
        "        if len(joined) > 1:\n",
        "            corr = joined[\"Peso_t1\"].corr(joined[\"Peso_t2\"])\n",
        "            print(f\"Correlation Peso {dates[0].date()} vs {d.date()}: {corr:.3f}\")"
      ],
      "metadata": {
        "id": "vtz2L9vvGMOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Fun√ß√£o auxiliar para plotar correla√ß√£o com linha de regress√£o\n",
        "def plot_corr(ax, x, y, x_label, y_label):\n",
        "    # Scatter\n",
        "    ax.scatter(x, y)\n",
        "\n",
        "    # Linha de regress√£o\n",
        "    m, b = np.polyfit(x, y, 1)\n",
        "    ax.plot(x, m * x + b)\n",
        "\n",
        "    # Correla√ß√£o de Pearson\n",
        "    r, p = pearsonr(x, y)\n",
        "\n",
        "    ax.set_title(f\"{x_label} √ó {y_label}\\nPearson r = {r:.3f}, p = {p:.3g}\")\n",
        "    ax.set_xlabel(x_label)\n",
        "    ax.set_ylabel(y_label)\n",
        "    ax.grid(True)\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# Subplots lado a lado\n",
        "# ===========================\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Gr√°fico 1 ‚Äî data1 x data2\n",
        "plot_corr(\n",
        "    ax=axes[0],\n",
        "    #x = dados[dados[\"Datad\"] == \"2004-07-08\"],\n",
        "    x = dados.loc[dados[\"Datad\"] == \"2004-07-08\", \"ps\"],\n",
        "    y = dados.loc[dados[\"Datad\"] == \"2005-01-10\", \"ps\"],\n",
        "    x_label=\"2004-07-08\",\n",
        "    y_label=\"2005-01-10\"\n",
        ")\n",
        "\n",
        "# Gr√°fico 2 ‚Äî data1 x data3\n",
        "plot_corr(\n",
        "    ax=axes[1],\n",
        "    x = dados.loc[dados[\"Datad\"] == \"2004-07-08\", \"ps\"],\n",
        "    y = dados.loc[dados[\"Datad\"] == \"2007-02-02\", \"ps\"],\n",
        "    x_label=\"2004-07-08\",\n",
        "    y_label=\"2007-02-02\"\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zNhl0m2OfsVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado mostra as correla√ß√µes entre os pesos medidos em diferentes datas para o mesmo conjunto de indiv√≠duos, e pode ser interpretado assim:\n",
        "\n",
        "* As datas indicam os momentos de medi√ß√£o: 08/07/2004, 10/01/2005, 24/10/2005, 02/02/2007 e 17/05/2007.\n",
        "\n",
        "* As correla√ß√µes (r) indicam o grau de associa√ß√£o linear entre o peso inicial (de 2004-07-08) e os pesos medidos nas datas seguintes.\n",
        "\n",
        "|Compara√ß√£o\t|Correla√ß√£o (r)\t|Interpreta√ß√£o|\n",
        "|:--|:--|:--|\n",
        "|2004-07-08 √ó 2005-01-10|\t0.732\t|Correla√ß√£o alta e positiva. Os animais mais pesados em 2004 tendem a continuar mais pesados em 2005.|\n",
        "|2004-07-08 √ó 2005-10-24|\t0.460\t|Correla√ß√£o moderada. A associa√ß√£o enfraquece um pouco com o tempo.|\n",
        "|2004-07-08 √ó 2007-02-02|\t0.303\t|Correla√ß√£o baixa. Indicando que, ap√≥s quase 3 anos, o peso inicial tem pouca rela√ß√£o com o peso atual.|\n",
        "|2004-07-08 √ó 2007-05-17|\t0.337\t|Tamb√©m baixa, refor√ßando a tend√™ncia de perda de depend√™ncia ao longo do tempo.|\n",
        "\n",
        "**üìä S√≠ntese estat√≠stica**\n",
        "* Esse padr√£o √© t√≠pico de dados longitudinais. A correla√ß√£o entre medidas repetidas de um mesmo indiv√≠duo tende a decrescer √† medida que o intervalo temporal aumenta.\n",
        "* Isso justifica o uso de modelos mistos ou estruturas de covari√¢ncia (como autoregressiva AR(1)) em an√°lises de medidas repetidas, pois assumem exatamente esse comportamento:\n",
        "**medidas pr√≥ximas no tempo s√£o mais correlacionadas do que medidas distantes.**"
      ],
      "metadata": {
        "id": "8e7bVSJjUY7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ajuste dos modelos fixos\n",
        "###    a) Modelo de Intercepto Aleat√≥rio (approx simcomp.ran)\n",
        "###    b) Modelo de Intercepto + Inclina√ß√£o Aleat√≥rios (approx AR(1) or more complex)"
      ],
      "metadata": {
        "id": "M_K1ql2Xqc8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a) Random intercept per Animal (and nested group approximation via group var)\n",
        "formula = \"Peso ~ Raca_touro * Datad_num\"\n",
        "md_intercept = mixedlm(formula, dados, groups=dados[\"Animal\"])\n",
        "m_intercept = md_intercept.fit(reml=True)\n",
        "print(\"\\n--- Random intercept model (MixedLM) ---\")\n",
        "print(m_intercept.summary())\n",
        "\n",
        "# Predictions and diagnostic plot\n",
        "dados[\"pred_intercept\"] = m_intercept.fittedvalues\n",
        "plt.scatter(dados[\"Peso\"], dados[\"pred_intercept\"])\n",
        "plt.plot([dados[\"Peso\"].min(), dados[\"Peso\"].max()], [dados[\"Peso\"].min(), dados[\"Peso\"].max()], 'r--')\n",
        "plt.xlabel(\"Observed Peso\")\n",
        "plt.ylabel(\"Predicted Peso (intercept model)\")\n",
        "plt.title(\"Observed vs Predicted (random intercept)\")\n",
        "plt.savefig(\"obs_vs_pred_intercept.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# b) Random intercept + random slope on Datad_num (may fail to converge on some datasets)\n",
        "md_slope = mixedlm(\"Peso ~ Raca_touro * Datad_num\", dados, groups=dados[\"Animal\"], re_formula=\"~Datad_num\")\n",
        "try:\n",
        "    m_slope = md_slope.fit(reml=True, method=\"lbfgs\", maxiter=2000)\n",
        "    converged = m_slope.mle_retvals.get(\"converged\", True)\n",
        "except Exception as e:\n",
        "    print(\"Random slope model failed to converge, retrying simplified fit or alternative optimizer.\", e)\n",
        "    try:\n",
        "        m_slope = md_slope.fit(reml=True, method=\"powell\", maxiter=1000)\n",
        "        converged = True\n",
        "    except Exception as e2:\n",
        "        print(\"Second attempt failed:\", e2)\n",
        "        m_slope = None\n",
        "        converged = False\n",
        "\n",
        "if m_slope is not None:\n",
        "    print(\"\\n--- Random slope model (MixedLM) ---\")\n",
        "    print(m_slope.summary())\n",
        "    dados[\"pred_slope\"] = m_slope.fittedvalues\n",
        "    plt.scatter(dados[\"Peso\"], dados[\"pred_slope\"])\n",
        "    plt.plot([dados[\"Peso\"].min(), dados[\"Peso\"].max()], [dados[\"Peso\"].min(), dados[\"Peso\"].max()], 'r--')\n",
        "    plt.xlabel(\"Observed Peso\")\n",
        "    plt.ylabel(\"Predicted Peso (slope model)\")\n",
        "    plt.title(\"Observed vs Predicted (random slope)\")\n",
        "    plt.savefig(\"obs_vs_pred_slope.png\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Random slope model unavailable due to convergence issues.\")"
      ],
      "metadata": {
        "id": "caTBa3nhGN9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üß† Contexto do modelo**\n",
        "\n",
        "* Vari√°vel dependente: Peso\n",
        "* Fatores fixos: Ra√ßa do touro (com n√≠veis ‚ÄúNelore‚Äù, ‚ÄúTabapu√£‚Äù e a refer√™ncia, provavelmente ‚ÄúGir‚Äù ou ‚ÄúBrahman‚Äù) e Data (Datad_num), uma vari√°vel num√©rica representando o tempo.\n",
        "* Agrupamento aleat√≥rio: indiv√≠duos (grupos = 24), cada um com 5 medidas (120 observa√ß√µes).\n",
        "* Ou seja: voc√™ est√° modelando a evolu√ß√£o do peso ao longo do tempo, considerando que cada animal tem medidas repetidas, e que as ra√ßas podem afetar o peso inicial e a velocidade de ganho de peso.\n",
        "\n",
        "**üìä Modelo de Intercepto Aleat√≥rio**\n",
        "Efeitos fixos\n",
        "|Termo\t|Interpreta√ß√£o\t|Resultado|\n",
        "|:--|:--|:--|\n",
        "|Intercept |(160.081, p$<$0.001)\t|Peso m√©dio inicial no grupo de refer√™ncia (ra√ßa base) no in√≠cio do per√≠odo.\tSignificativo.|\n",
        "|Raca_touro[T.Nelore] |(-12.38, p=0.407)\t|Em m√©dia, animais Nelore come√ßam 12,4 kg mais leves que o grupo de refer√™ncia, mas a diferen√ßa n√£o √© significativa.\t|\n",
        "|Raca_touro[T.Tabapua] |(-22.16, p=0.138)|\tTabapu√£ come√ßa cerca de 22 kg mais leve que o grupo de refer√™ncia, tamb√©m n√£o significativo.\t|\n",
        "|Datad_num |(0.394, p$<$0.001)\t|O peso aumenta 0,394 kg por unidade de tempo (provavelmente por dia ou m√™s), de forma significativa.\t|\n",
        "|Intera√ß√£o Nelore√óData |(0.033, p=0.065)\t|Tend√™ncia de crescimento ligeiramente mais r√°pida nos Nelore, quase significativa (p‚âà0.065).\t|\n",
        "|Intera√ß√£o Tabapua√óData |(-0.009, p=0.615)\t|Tabapu√£ n√£o difere da ra√ßa de refer√™ncia no ritmo de ganho de peso.\t|\n",
        "\n",
        "üí° S√≠ntese:\n",
        "* H√° crescimento consistente do peso ao longo do tempo.\n",
        "* As diferen√ßas entre ra√ßas s√£o pequenas e n√£o significativas no peso inicial.\n",
        "* Pode haver uma tend√™ncia leve de crescimento mais r√°pido nos Nelore (quase significativa).\n",
        "\n",
        "Efeitos aleat√≥rios\n",
        "\n",
        "* Group Var = 323.34 ‚Üí indica alta variabilidade entre indiv√≠duos no peso inicial (interceptos diferentes).\n",
        "* Isso justifica o uso do intercepto aleat√≥rio.\n",
        "\n",
        "**üìà Random Intercept + Random Slope Model**\n",
        "\n",
        "Esse modelo permite que cada animal tenha n√£o s√≥ peso inicial diferente, mas tamb√©m uma inclina√ß√£o (ritmo de ganho) diferente.\n",
        "\n",
        "Efeitos fixos\n",
        "\n",
        "* Os coeficientes s√£o praticamente id√™nticos, o que √© bom ‚Äî significa que o modelo mais complexo n√£o distorceu os efeitos principais.\n",
        "* O crescimento ao longo do tempo (Datad_num) permanece fortemente significativo (p$<$0.001).\n",
        "* A intera√ß√£o Nelore√ótempo continua marginalmente significativa (p‚âà0.084).\n",
        "* A intera√ß√£o Tabapu√£√ótempo segue n√£o significativa.\n",
        "\n",
        "Efeitos aleat√≥rios\n",
        "|Termo\t|Interpreta√ß√£o|\n",
        "|:--|:--|\n",
        "|Group Var = 112.75\t|Vari√¢ncia entre interceptos (peso inicial) diminuiu. Parte da varia√ß√£o foi explicada pelo acr√©scimo de slopes.|\n",
        "|Group √ó Datad_num Cov = 0.166\t|Correla√ß√£o positiva entre intercepto e inclina√ß√£o ‚Üí indiv√≠duos que come√ßam mais pesados tendem a ganhar um pouco mais de peso ao longo do tempo.|\n",
        "|Datad_num Var = 0.000\t|A vari√¢ncia das inclina√ß√µes √© muito pequena, sugerindo que as diferen√ßas no ritmo de crescimento entre indiv√≠duos s√£o m√≠nimas.|\n",
        "|Scale = 1000.47 vs 1063.16\t|Pequena melhora no ajuste.|\n",
        "\n",
        "**‚öñÔ∏è Compara√ß√£o entre modelos**\n",
        "|M√©trica\t|Random Intercept\t|Random Intercept + Slope|\n",
        "|:--|:--|:--|\n",
        "|Log-Likelihood\t|-597.80\t|-596.12|\n",
        "|ŒîLogLik\t|+1.68\t|‚Äî|\n",
        "|AIC (aprox.)\t|1205.6\t|1204.2|\n",
        "\n",
        "üëâ A melhora √© muito pequena (ŒîAIC < 2), e a vari√¢ncia da inclina√ß√£o aleat√≥ria praticamente zero, o que indica que o modelo mais complexo n√£o agrega muito.\n",
        "Portanto, o modelo de intercepto aleat√≥rio √© suficiente para descrever a estrutura dos dados.\n",
        "\n",
        "**üßæ 5. Conclus√£o interpretativa**\n",
        "* O peso aumenta de forma significativa ao longo do tempo, com taxa m√©dia de 0,394 kg/unidade de tempo.\n",
        "* N√£o h√° diferen√ßas estatisticamente significativas entre as ra√ßas no peso inicial.\n",
        "* Pode haver uma tend√™ncia de crescimento um pouco mais r√°pido em Nelore, mas marginal.\n",
        "* As diferen√ßas entre indiv√≠duos s√£o reais e relevantes (interceptos aleat√≥rios significativos).\n",
        "* O modelo com inclina√ß√£o aleat√≥ria n√£o melhora substancialmente o ajuste, sugerindo que o ritmo de ganho de peso √© semelhante entre os animais, ainda que com diferentes pesos iniciais."
      ],
      "metadata": {
        "id": "W-axOXK4xS5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.sandbox.predict_functional import predict_functional\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Escolha do modelo ajustado\n",
        "# -----------------------------------------------------\n",
        "model = m_intercept  # ou m_slope, se preferir comparar\n",
        "dados[\"Predito\"] = model.predict()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 1Ô∏è‚É£ Curvas ajustadas m√©dias com intervalo de confian√ßa\n",
        "# -----------------------------------------------------\n",
        "\n",
        "# Gera uma sequ√™ncia de valores de tempo (Datad_num)\n",
        "tempo_grid = np.linspace(dados[\"Datad_num\"].min(), dados[\"Datad_num\"].max(), 100)\n",
        "\n",
        "# Obt√©m as ra√ßas √∫nicas\n",
        "racas = dados[\"Raca_touro\"].unique()\n",
        "\n",
        "pred_list = []\n",
        "for r in racas:\n",
        "    tmp = pd.DataFrame({\n",
        "        \"Raca_touro\": [r] * len(tempo_grid),\n",
        "        \"Datad_num\": tempo_grid\n",
        "    })\n",
        "    pred_mean = model.predict(tmp)\n",
        "\n",
        "    # --- Intervalo de confian√ßa aproximado 95% ---\n",
        "    # Usando vari√¢ncia dos res√≠duos e tamanho da amostra\n",
        "    se = np.sqrt(model.scale / len(dados))\n",
        "    ci_upper = pred_mean + 1.96 * se\n",
        "    ci_lower = pred_mean - 1.96 * se\n",
        "\n",
        "    pred_list.append(pd.DataFrame({\n",
        "        \"Raca_touro\": r,\n",
        "        \"Datad_num\": tempo_grid,\n",
        "        \"Peso_pred\": pred_mean,\n",
        "        \"CI_lower\": ci_lower,\n",
        "        \"CI_upper\": ci_upper\n",
        "    }))\n",
        "\n",
        "pred_df = pd.concat(pred_list)\n",
        "\n",
        "# --- Plot ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=pred_df, x=\"Datad_num\", y=\"Peso_pred\", hue=\"Raca_touro\", lw=2)\n",
        "plt.fill_between(\n",
        "    pred_df[\"Datad_num\"],\n",
        "    pred_df[\"CI_lower\"],\n",
        "    pred_df[\"CI_upper\"],\n",
        "    alpha=0.15,\n",
        "    color=\"gray\",\n",
        "    label=\"95% IC (aprox.)\"\n",
        ")\n",
        "plt.title(\"Curvas m√©dias ajustadas com intervalo de confian√ßa (Modelo Misto)\")\n",
        "plt.xlabel(\"Tempo (Datad_num)\")\n",
        "plt.ylabel(\"Peso predito (kg)\")\n",
        "plt.legend(title=\"Ra√ßa do touro\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2Ô∏è‚É£ Curvas individuais (efeitos aleat√≥rios)\n",
        "# -----------------------------------------------------\n",
        "plt.figure(figsize=(10, 6))\n",
        "for animal, grupo in dados.groupby(\"Animal\"):\n",
        "    plt.plot(grupo[\"Datad_num\"], grupo[\"Predito\"], alpha=0.3, lw=1, color=\"gray\")\n",
        "\n",
        "sns.lineplot(data=pred_df, x=\"Datad_num\", y=\"Peso_pred\", hue=\"Raca_touro\", lw=2)\n",
        "plt.title(\"Curvas individuais e m√©dias ajustadas ‚Äì Modelo Misto\")\n",
        "plt.xlabel(\"Tempo (Datad_num)\")\n",
        "plt.ylabel(\"Peso predito (kg)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3Ô∏è‚É£ Compara√ß√£o entre modelos (opcional)\n",
        "# -----------------------------------------------------\n",
        "dados[\"Predito_slope\"] = m_slope.predict()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=dados, x=\"Datad_num\", y=\"Peso\", alpha=0.3, label=\"Observado\")\n",
        "sns.lineplot(data=dados, x=\"Datad_num\", y=\"Predito\", color=\"blue\", lw=2, label=\"Intercepto aleat√≥rio\")\n",
        "sns.lineplot(data=dados, x=\"Datad_num\", y=\"Predito_slope\", color=\"red\", lw=2, label=\"Intercepto + inclina√ß√£o\")\n",
        "plt.title(\"Compara√ß√£o dos modelos mistos\")\n",
        "plt.xlabel(\"Tempo (Datad_num)\")\n",
        "plt.ylabel(\"Peso (kg)\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_NN64T1s0XjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üß† Interpreta√ß√£o visual**\n",
        "\n",
        "* Curvas m√©dias (com IC): mostram a tend√™ncia geral por ra√ßa ao longo do tempo, com a faixa cinza indicando a incerteza da estimativa.\n",
        "* Curvas individuais: permitem ver como cada animal se desvia da m√©dia, capturando a variabilidade aleat√≥ria.\n",
        "* Compara√ß√£o de modelos: ajuda a visualizar se o modelo com random slope (linhas vermelhas) acompanha melhor os dados observados que o de intercepto aleat√≥rio."
      ],
      "metadata": {
        "id": "9r9PCALR08q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 5. Fit GLS approximations (optional)\n",
        "#    Note: statsmodels does not have a direct GLS with corCompSymm or corAR1 per group as in nlme.\n",
        "#    We show an example using GLSAR on aggregated / pseudo-time series (not exact analogue).\n",
        "# ---------------------------\n",
        "# Example: aggregate by animal into wide format and compute covariance matrix / explore\n",
        "# (left here as optional advanced exercise)\n"
      ],
      "metadata": {
        "id": "Aef-_u99GQcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compara√ß√£o dos Modelos (AIC/BIC & LRT quando aplic√°vel)\n"
      ],
      "metadata": {
        "id": "KlS_R6nr382d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_model_info(model, name):\n",
        "    logLik = model.llf\n",
        "    n_params = model.df_modelwc\n",
        "    n_obs = model.nobs\n",
        "    AIC = -2 * logLik + 2 * n_params\n",
        "    BIC = -2 * logLik + np.log(n_obs) * n_params\n",
        "    return {\"model\": name, \"logLik\": logLik, \"AIC\": AIC, \"BIC\": BIC}\n",
        "\n",
        "info_int = extract_model_info(m_intercept, \"Intercept\")\n",
        "info_slope = extract_model_info(m_slope, \"Slope\")\n",
        "\n",
        "comparison = pd.DataFrame([info_int, info_slope])\n",
        "print(\"\\n=== Model comparison (AIC/BIC) ===\")\n",
        "print(comparison)\n",
        "\n",
        "# ---------------------------\n",
        "#  Escolher modelo preferido\n",
        "# ---------------------------\n",
        "model_chosen = m_intercept if comparison.loc[0, \"AIC\"] <= comparison.loc[1, \"AIC\"] else m_slope\n",
        "print(f\"\\nModelo selecionado: {model_chosen.model.data.design_info.describe()}\")"
      ],
      "metadata": {
        "id": "4dA1IqPz3psr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diagn√≥sticos de res√≠duos (para o modelo escolhido. Usa o intercepto aleat√≥rio por padr√£o."
      ],
      "metadata": {
        "id": "MhbazufN5aiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_chosen = m_intercept if (m_slope is None or not converged) else m_slope\n",
        "resid = model_chosen.resid\n",
        "print(\"\\nShapiro-Wilk test for residual normality:\", shapiro(resid))\n",
        "print(\"Durbin-Watson:\", durbin_watson(resid))\n",
        "\n",
        "# Levene test across dates (homogeneity)\n",
        "groups_for_levene = [dados.loc[dados[\"Datad\"]==d, \"Peso\"].values for d in dados[\"Datad\"].unique()]\n",
        "if len(groups_for_levene) > 1:\n",
        "    print(\"Levene test across dates:\", levene(*groups_for_levene))\n",
        "\n",
        "plt.figure()\n",
        "sns.histplot(resid, kde=True)\n",
        "plt.title(\"Residuals histogram\")\n",
        "plt.savefig(\"resid_hist.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Residuals by date boxplot\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.boxplot(x=\"Datad\", y=resid, data=dados)\n",
        "plt.xticks(rotation=30)\n",
        "plt.title(\"Residuals by Date\")\n",
        "plt.savefig(\"resid_by_date.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E0A4UYYbGTUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 8. Estimated marginal means (LS-means) and pairwise comparisons\n",
        "#    We compute LS-means for each Raca_touro adjusting Datad_num at its mean.\n",
        "# ---------------------------\n",
        "def lsmeans_from_mixedlm(model, data, factor, covariates=None):\n",
        "    \"\"\"\n",
        "    Compute approximate least-squares means for levels of 'factor' by predicting\n",
        "    at covariates fixed at their mean. Returns DataFrame with mean, SE, CI.\n",
        "    \"\"\"\n",
        "    levels = data[factor].cat.categories\n",
        "    covariates = covariates or []\n",
        "    rows = []\n",
        "    # base covariate values (means)\n",
        "    cov_means = {c: data[c].mean() for c in covariates}\n",
        "    for lvl in levels:\n",
        "        # build new dataframe for prediction\n",
        "        df_new = pd.DataFrame({factor:[lvl]})\n",
        "        for c in covariates:\n",
        "            df_new[c] = cov_means[c]\n",
        "        # add any other categorical factors as reference from data (not implemented here)\n",
        "        # Use model.predict(exog) - need to construct right design matrix\n",
        "        # Easiest: use patsy to build design matrix\n",
        "        import patsy\n",
        "        exog = patsy.dmatrix(model.model.data.orig_exog.design_info.builder, df_new, return_type='dataframe') \\\n",
        "               if False else None\n",
        "        # simpler approach: use model.model.predict with formula-based evaluation\n",
        "        try:\n",
        "            pred = model.predict(df_new)[0]\n",
        "            # get standard error via get_prediction if available\n",
        "            try:\n",
        "                pred_obj = model.get_prediction(df_new)\n",
        "                se = pred_obj.se_mean[0]\n",
        "                ci_low, ci_upp = pred_obj.conf_int(alpha=0.05).iloc[0]\n",
        "            except Exception:\n",
        "                se = np.nan\n",
        "                ci_low, ci_upp = (np.nan, np.nan)\n",
        "        except Exception:\n",
        "            # fallback: construct a row with full set of variables using mean levels\n",
        "            # (This fallback may need tailoring depending on model formula)\n",
        "            pred = np.nan\n",
        "            se = np.nan\n",
        "            ci_low, ci_upp = (np.nan, np.nan)\n",
        "        rows.append({\"level\": lvl, \"lsmean\": pred, \"se\": se, \"ci_low\": ci_low, \"ci_upp\": ci_upp})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# compute lsmeans for Raca_touro adjusting Datad_num\n",
        "lsm = lsmeans_from_mixedlm(model_chosen, dados, factor=\"Raca_touro\", covariates=[\"Datad_num\"])\n",
        "print(\"\\nLS-means (approx):\")\n",
        "print(lsm)\n",
        "\n",
        "# Pairwise differences (approx) using predicted means and their se (normal approx)\n",
        "def pairwise_lsmeans(df_ls):\n",
        "    res = []\n",
        "    for a,b in combinations(df_ls['level'],2):\n",
        "        ra = df_ls[df_ls['level']==a].iloc[0]\n",
        "        rb = df_ls[df_ls['level']==b].iloc[0]\n",
        "        diff = ra['lsmean'] - rb['lsmean']\n",
        "        # naive se: sqrt(se_a^2 + se_b^2) (ignoring covariance)\n",
        "        se_diff = np.sqrt((ra['se'] if not np.isnan(ra['se']) else 0)**2 + (rb['se'] if not np.isnan(rb['se']) else 0)**2)\n",
        "        tstat = diff / se_diff if se_diff>0 else np.nan\n",
        "        # degrees freedom approx: use model_chosen.df_resid\n",
        "        from scipy.stats import t\n",
        "        df_res = model_chosen.df_resid\n",
        "        pval = 2*(1 - t.cdf(np.abs(tstat), df_res)) if not np.isnan(tstat) else np.nan\n",
        "        res.append({\"pair\":f\"{a} vs {b}\", \"diff\":diff, \"se_diff\":se_diff, \"t\":tstat, \"p\":pval})\n",
        "    return pd.DataFrame(res)\n",
        "\n",
        "pw = pairwise_lsmeans(lsm)\n",
        "print(\"\\nPairwise comparisons (approx):\")\n",
        "print(pw)"
      ],
      "metadata": {
        "id": "MnaeQLg3GVAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üßÆ 1Ô∏è‚É£ LS-means (m√©dias ajustadas):**\n",
        "\n",
        "|Ra√ßa\t|LS-mean (Peso ajustado)|\n",
        "|:--|:--|\n",
        "|Brahman\t|367.98 kg|\n",
        "|Nelore\t|372.98 kg|\n",
        "|Tabapu√£\t|341.08 kg|\n",
        "\n",
        "Interpreta√ß√£o:\n",
        "\n",
        "* Ap√≥s ajustar o modelo misto (controlando o efeito aleat√≥rio dos grupos e o tempo), a ra√ßa Nelore apresenta o maior peso m√©dio ajustado ($\\sim$ 373 kg), seguida de Brahman ($\\sim$ 368 kg) e Tabapu√£ ($\\sim$ 341 kg).\n",
        "\n",
        "* Isso sugere uma diferen√ßa potencialmente relevante entre Tabapu√£ e as demais ra√ßas. Os animais Tabapu√£ estariam com menor peso ajustado."
      ],
      "metadata": {
        "id": "JvQH8-Vj6NqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 9. Outlier removal by residual IQR and re-fit (optional)\n",
        "# ---------------------------\n",
        "q1, q3 = np.nanpercentile(resid, [25,75])\n",
        "iqr = q3 - q1\n",
        "lower = q1 - 1.5*iqr\n",
        "upper = q3 + 1.5*iqr\n",
        "mask = (resid >= lower) & (resid <= upper)\n",
        "print(f\"Removing {np.sum(~mask)} observations as residual outliers\")\n",
        "dados_clean = dados.loc[mask].copy()\n",
        "\n",
        "# Refit chosen model on cleaned data\n",
        "md_clean = mixedlm(formula, dados_clean, groups=dados_clean[\"Animal\"])\n",
        "m_clean = md_clean.fit(reml=True)\n",
        "print(\"\\nRefitted model after removing outliers:\")\n",
        "print(m_clean.summary())"
      ],
      "metadata": {
        "id": "Xukk9JdgGXa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 10. Final ANOVA table for fixed effects (Type II/III)\n",
        "# ---------------------------\n",
        "# We can use statsmodels to get anova on the underlying OLS (approximation) or use Wald tests\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "# Build equivalent OLS for fixed effects table (approx)\n",
        "ols_approx = smf.ols(\"Peso ~ Raca_touro * Datad_num\", data=dados).fit()\n",
        "print(\"\\nANOVA table (OLS approximation):\")\n",
        "print(anova_lm(ols_approx, typ=2))\n",
        "\n",
        "# ---------------------------\n",
        "# End: print summary of chosen model\n",
        "# ---------------------------\n",
        "print(\"\\nFinal chosen model summary:\")\n",
        "print(model_chosen.summary())\n"
      ],
      "metadata": {
        "id": "zbixYSIqGZKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1Ô∏è‚É£ ANOVA (OLS approximation)**\n",
        "|Fonte\t|F\t|p-valor\t|Interpreta√ß√£o|\n",
        "|:--|:--|:--|:--|\n",
        "|Raca_touro\t|8.65\t|0.0003175\t|H√° diferen√ßa significativa no peso m√©dio entre ra√ßas de touro, sem ajustar para efeito|"
      ],
      "metadata": {
        "id": "f06b6d1u66pR"
      }
    }
  ]
}